<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a demo site for Nikola.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Epsilon Heap</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="canonical" href="https://epsilonheap.github.io/">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><link rel="prefetch" href="posts/wellspring-of-innovation/" type="text/html">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="https://epsilonheap.github.io/">

            <span id="blog-title">Epsilon Heap</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav"></ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="#" class="nav-link">Blog</a>
                </li>
<li class="nav-item">
<a href="pages/home/index.html" class="nav-link">Pages</a>
                </li>
<li class="nav-item">
<a href="gatsby-dir/index.html" class="nav-link">Gatsby</a>
                </li>
<li class="nav-item">
<a href="archive.html" class="nav-link">Archives</a>
                </li>
<li class="nav-item">
<a href="categories/index.html" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="rss.xml" class="nav-link">RSS feed</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
    
        

    
        
    <div class="postindex">
            <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/wellspring-of-innovation/" class="u-url">Wellspring of Innovation</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Your Name
                    </span></p>
            <p class="dateline">
            <a href="posts/wellspring-of-innovation/" rel="bookmark">
            <time class="published dt-published" datetime="2019-02-15T15:08:00Z" itemprop="datePublished" title="2019-02-15 15:08">2019-02-15 15:08</time></a>
            </p>
                        <p class="commentline">
        
    <a href="posts/wellspring-of-innovation/#disqus_thread" data-disqus-identifier="cache/posts/wellspring-of-innovation.html">Comments</a>


                </p>
</div>
            </header><div class="e-content entry-content">
                    <div>
<h2>Manufacturing Innovation?</h2>
<p>That rarest product of intellectual activities, original innovation, is often serendipitous. Many organizations are well aware of the elusive nature of innovation and yet persists in the pursuit of research and development (jokingly depicted as <a href="https://www.google.com/search?tbm=isch&amp;sa=1&amp;ei=1ttmXOaMMuKGggfI9oyYCw&amp;q=far+side+cat+herding+cartoons&amp;oq=far+side+cat+herding+cartoons&amp;gs_l=img.3...0.0..27395...0.0..0.0.0.......1......gws-wiz-img.HTpJM9I9_yk">herding cats</a>) in hopes of finding 'the next big thing'. One approach that has demonstrated success is to cultivate a certain culture and attract individuals with specific characteristics to foster a 'breeding' ground for creative risk-taking. Noted omissions are the mention of 'experience', 'skill-set', or knowledge of specific technologies or academic subjects: a deliberate choice. The intended differentiation is to separate products of intellectual activities or processes from the factors that drive innovation. Again, the emphasis is not refinement nor incremental improvements but finding something 'new'. Find people that will find a way forward, even (or especially) if they don't know what they are doing.</p>
<h2>"Taste"</h2>
<p>Two examples of organizations that have engineered innovation on a large-scale are Bell Labs and Xerox. There are others but these two seem particularly influential. One common theme shared by the two is the rather nebulous word "taste".</p>
<p><a href="http://www.johnseelybrown.com/">John Seely Brown</a> (JSB) ran Xerox's research organization during my time there. <a href="https://www.youtube.com/watch?v=amdONcqQvnU">Here</a> is a fun and informative video of his take on research at Xerox. JSB uses a triad of aspiration, imagination, and intuition as pillars supporting his concept of 'taste'. The culture that he described was real and clearly evident in how research managers operated - <a href="https://www.xerox.com/en-us/about/executive-leadership/corporate-officers/steve-hoover-biography">Steve Hoover</a>, now CTO at Xerox, expounded these same core ideas when our discussions turned to how research was done at Xerox.
JSB's description of the preference for 'edge' workers and the importance of 'taste' is traditional and was passed down from the days of <a href="https://www.wired.com/2017/04/youve-never-heard-tech-legend-bob-taylor-invented-almost-everything/">Robert Taylor</a>.</p>
<p>Yet another legendary organization was Bell Labs. <a href="https://history.computer.org/pioneers/hamming.html">Richard Hamming</a> was in the thick of things there and gave a personalized set of lectures (which starts <a href="https://www.youtube.com/watch?v=AD4b-52jtos">here</a>) on being successful in intellectual pursuits.  He also mentioned 'taste' as being vital to channeling efforts into good work.</p>
<h2>From Elusive to Vague</h2>
<p>So ... an elusive goal (innovation) could very well be the product of some vague notion (taste), amongst other things. Not helpful. Then let's see what other thinking are not helpful?</p>
<p>An over reliance on pure technical abilities or specific knowledge as indicative of likely success. Science and technologies are evolving fast and paying heed to <a href="https://quoteinvestigator.com/2014/05/04/adapt/">Darwin</a> may be good advice: adaptability should be a prized trait. From a cognitive perspective, adaptability is a manifestation of curiosity, imagination, discipline, and astuteness. Advice: spend your resources on finding individuals with these characteristics, not those who do well on coding challenges or did well in school (remember the stated goal is innovation.) A slide in JSB's talk clearly said: 'Never looked at a transcript'.</p>
<p>To wit: Tensorflow, in a short time-span, will have changed from one execution model (see <a href="https://medium.com/tensorflow/whats-coming-in-tensorflow-2-0-d3663832e9b8">medium article</a> and <a href="https://www.reddit.com/r/MachineLearning/comments/9ysmtn/d_debate_on_tensorflow_20_api/">reddit discussion</a>) to another, and users will have to essentially learn a new system. Yes, just one example, but this is not an isolated case. Technology may be fleeting, fundamentals have a much longer self-life.</p>
<p>Another would be 'high energy' disguised as motivation. Many people are motivated but not self-directed, and you need both. A self-directed individual needs guidance but not much management. Be careful to see aspiration in a clear light.</p>
<p>Lastly, do not dismiss but make room for intuition. This is one of those terms that are hard to define but not too difficult to recognize. Not too difficult because this trait is often expressed as a 'magical' ability to formulate solutions or ask the right questions. Ask hard, open-ended questions and observe what ensues. The answer doesn't have to be right, just penetrating or meandering towards plausible reasoning. Questions like those on an academic test (or puzzles if just a matter of memorization) that elicit some expected answers seldom highlight intuition.</p>
<hr>
</div>
                </div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/ensemble-trees/" class="u-url">Ensemble Trees</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Your Name
                    </span></p>
            <p class="dateline">
            <a href="posts/ensemble-trees/" rel="bookmark">
            <time class="published dt-published" datetime="2019-02-14T16:35:13Z" itemprop="datePublished" title="2019-02-14 16:35">2019-02-14 16:35</time></a>
            </p>
                        <p class="commentline">
        
    <a href="posts/ensemble-trees/#disqus_thread" data-disqus-identifier="cache/posts/ensemble-trees.html">Comments</a>


                </p>
</div>
            </header><div class="e-content entry-content">
                    <div>
<h2>Chasing the Deep End</h2>
<p>Deep this, deep that; not that there is anything wrong with that. Why? because deep neural-networks (now being referred to as <a href="https://www.facebook.com/yann.lecun/posts/10155003011462143">differential programming</a> by one of its pioneers) is one of milestone advancements in ML/AI and have many applications. So generally powerful and useful that it is now a fundamental design component for higher-level systems tailored for specific domains (see <a href="https://www.youtube.com/watch?v=QuELiw8tbx8">Stanford lecture</a> and <a href="https://www.youtube.com/watch?v=oGk1v1jQITw">Deep Learning School presentation</a> by <a href="https://www.socher.org/">Richard Sochar</a>). As an electrical engineer by academic title, this systems approach is comfortably familiar, very much like circuits design.</p>
<p>Another 'component' that has been very useful, powerful, and efficient falls under the category of ensemble trees - especially the <a href="https://en.wikipedia.org/wiki/Gradient_boosting">boosting</a> variant. In a sense, ensemble trees are both deep and wide. The number of tree layers control depth versus breath, and an ensemble overlay offer wide exploration of features and relationships to observed outcomes. Yet more 'deepness' could be had by employing a component approach where elements are wired together.</p>
<p>Table 10.1 of <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">'The Elements of Statistical Learning'</a> compares trees-based methods to some contemporaries. Although much progress has been been made since its publication, most of the characterizations still hold. In particular, efficiency, forbearance with regards to feature data, and interpretability are outstanding advantages. </p>
<h2>Results and Insights</h2>
<p>These qualities are differentiators where decisions are costly in terms of the cost of doing experiments, collecting data, and unsatisfactory consequences. Of course, mistakes are unavoidable and tree-base methods are typically less accurate, but being clueless about why something works or fails can be a <a href="https://www.risk.net/asset-management/6119616/blackrock-shelves-unexplainable-ai-liquidity-models">no go</a> - you cannot learn from your mistakes. For medical use, a lack of reasoning is not comforting. In a research setting, gaining insights from interpretable models are more useful than raw accuracy. Tree-based methods can also be applied early on as part of a systematic application of data science - they are good at taking available data without much preprocessing and identifying influential features. They are fast and relatively easy to use.</p>
<h2>Building on a Good Idea</h2>
<p>Ensembles, tree-based models, bagging, and boosting make for great companions. Some nifty variants on this combinations are:</p>
<ol>
<li>Random Forests</li>
<li>Xgboost</li>
<li>Catboost</li>
<li>mboost</li>
<li>gamboostLSS</li>
</ol>
<p>[annotate later]</p>
<hr>
</div>
                </div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/sparse-high-dimensional-regression/" class="u-url">Sparse High-Dimensional Regression</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Your Name
                    </span></p>
            <p class="dateline">
            <a href="posts/sparse-high-dimensional-regression/" rel="bookmark">
            <time class="published dt-published" datetime="2019-02-11T12:29:47Z" itemprop="datePublished" title="2019-02-11 12:29">2019-02-11 12:29</time></a>
            </p>
                        <p class="commentline">
        
    <a href="posts/sparse-high-dimensional-regression/#disqus_thread" data-disqus-identifier="cache/posts/sparse-high-dimensional-regression.html">Comments</a>


                </p>
</div>
            </header><div class="e-content entry-content">
                    <div>
<h2>What!?</h2>
<p>This one falls under the 'mind-bending' category that has initiated a personal re-examination of the whole practice of regression. Bertsimas and Van Parys released <a href="https://arxiv.org/abs/1709.10029">'Sparse High-Dimensional Regression: Exact Scalable Algorithms and Phase Transitions'</a> upon the world and upended my beliefs. </p>
<p><a href="http://www.mit.edu/~dbertsim/">Professor Bertsimas's</a> <a href="https://www.youtube.com/watch?v=7w9aRrYgGEs">Hotelling lecture</a> is a good video presentation of his approach to the topic.
[Note: Optimization is a foundational showcase of the power of computing - pay attention to this field.] An earlier paper <a href="https://arxiv.org/abs/1507.03133">'Best Subset Selection via a Modern Optimization Lens'</a> started the buzz and elicited Trevor Hastie, Robert Tibshirani, and Ryan Tibshirani to respond with <a href="https://arxiv.org/abs/1707.08692">'Extended Comparisons of Best Subset Selection, Forward Stepwise Selection, and the Lasso'</a>.</p>
<p>The problem: regression, although very useful, has always had some associated arbitrariness. Leo Brieman's dissatisfaction with the somewhat 'fickle' nature of statistical regression lead him to develop predictive methods based on algorithms rather than statistical models. One of Brieman's <a href="https://www.stat.berkeley.edu/~breiman/wald2002-2.pdf">Wald Lecture</a> describes the state of affairs that motivated his work. For instance, given the same data, practitioners would arrive at a multitude of different models with different predictor variables that should have similar predictive abilities. The problem was not with the skills of those doing the analysis (page 11 of lecture) but with the method itself. Bertsimas and Van Parys suggest that a more 'exact' approach could be at hand.</p>
<hr>
<h2>Mixed Integer Optimization (MIO)</h2>
<p>Loosely stated, MIO has been shown in practice to be highly efficient and effective in regularizing to the zero norm of a regression model; finding the support of the variables under selection. In theory, this should be a daunting prospect (NP-Complete) and rather hopeless for very high dimensional problems. This paper shows otherwise and hints at some sort of phase-transition taking place. Phase-transitions are typically associated with the universal behavior of matter in different phases undergoing a competition to reach stability near what are known as 'critical' points where both phases co-exist - again loosely stated.</p>
<p>MIO are mysterious to me and begs for study. What could constitute the two-phases (duality is two faces of the same problem)? What exactly are the mechanisms of MIO?</p>
<p>...</p>
<hr>
</div>
                </div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/kelly-with-drawdown/" class="u-url">Kelly with Drawdown</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Your Name
                    </span></p>
            <p class="dateline">
            <a href="posts/kelly-with-drawdown/" rel="bookmark">
            <time class="published dt-published" datetime="2019-02-07T20:43:54Z" itemprop="datePublished" title="2019-02-07 20:43">2019-02-07 20:43</time></a>
            </p>
                        <p class="commentline">
        
    <a href="posts/kelly-with-drawdown/#disqus_thread" data-disqus-identifier="cache/posts/kelly-with-drawdown.html">Comments</a>


                </p>
</div>
            </header><div class="e-content entry-content">
                    <div>
<h2>Kelly Gambling</h2>
<p>Portfolio management is a pillar of asset management. Given resources and many avenues for allocating said resources, how to allocate so as to achieve a desired effect? With regards to money, more is considered best, and with little chance of losing much would be ideal. Two views have received considerable attention on this topic. One approach is known as '<a href="https://www.investopedia.com/terms/m/modernportfoliotheory.asp">Modern Portfolio Theory</a>' and the other is '<a href="https://www.investopedia.com/articles/trading/04/091504.asp">Kelly Criterion</a>'. Warren Buffet <a href="http://undergroundvalue.blogspot.com/2008/02/notes-from-buffett-meeting-2152008_23.html">explains</a> the difference when asked by students: take advantage of an 'edge' where possible, and seek safety in numbers otherwise.</p>
<p>Modern Portfolio Theory is taught in academia, and Kelly Criterion is mostly a method encountered by those asking 'is there another way?' This article on <a href="https://ergodicityeconomics.com/2018/02/16/the-trouble-with-bernoulli-1738/#more-3206">Bernoulli</a> and another on <a href="https://ergodicityeconomics.com/2017/07/18/doing-a-laplace/#more-102">Laplace</a> examine the fundamental difference of the two views and advocates for the Kelly approach. The latter article explains why the Kelly approach is less well known. Incidently, the criterion named after John Kelly is an of application of Claude Shannon's work to gambling - as detailed by <a href="http://home.williampoundstone.net/Kelly.htm">William Poundstone</a>. Yet another area Leo Breiman focused his energy was with <a href="https://projecteuclid.org/euclid.bsmsp/1200512159">'Optimal Gambling Systems for Favorable Games'</a> where he explored the idea introduced by Kelly. <a href="http://www-isl.stanford.edu/~cover/portfolio-theory.html">Thomas Cover</a> of information theory fame also examined the subject matter as well.</p>
<p>Enzo Busseti, Ernest Ryu, and <a href="http://web.stanford.edu/~boyd/">Stephen Boyd</a> (who oversees several areas of exciting research) published '<a href="https://arxiv.org/abs/1603.06183">Risk-Constrained Kelly Gambling</a>' which derives an approach to incorporate <a href="https://www.investopedia.com/terms/d/drawdown.asp">drawdown</a> with Kelly gambling. When speaking of risks, drawdown would be top of the list for many - more so when following a Kelly approach. With concentrated positions, the prospects of some big bets going awry would be disastrous whereas a highly diversified portfolio would suffer the same fate as the market as a whole. This paper combines Kelly gambling with risk aversion in a systematic way, and do so by casting the problem as <a href="http://web.stanford.edu/~boyd/cvxbook/">convex optimization</a>.</p>
<p>$$
\begin{array}{cl}
maximize &amp; \mathbb{E}\log({r^\intercal b}) \cr[2ex]
subject \; to &amp; \begin{aligned}
\mathbb{E}(r^\intercal b)^{-\lambda} &amp; \leq 1 \cr
\mathbb{I}^\intercal b &amp; = 1, b \geq 0
\end{aligned}
\end{array}
$$</p>
<p>where \(r\) is a matrix of returns for a set of investments, \(b\) is a vector of allocations, and \(r^\intercal b\) is then the gain in wealth of a portfolio. \( \mathbb{E}(r^\intercal b)^{-\lambda} \leq 1 \) will be expanded upon later. This constraint effectively bounds how much risk one is willing to take.</p>
<p>A key result of the paper is that \( \mathbb{E}(r^\intercal b)^{-\lambda} \leq 1 \Rightarrow \mathbb{Prob}(W^{min} \lt \alpha) \lt \beta\). That is, the probability \(W^{min}\), a random variable of the minimum wealth, of being less that \(\alpha\) is less than \(\beta\), and is equivalent to the aforementioned 'degree' of risk constraint. A different symbolic way to see the interplay of \(\alpha, \: \beta, \: and, \: \lambda \) is \( \mathbb{Prob}(W^{min} \lt \alpha) \lt \alpha^\lambda = \beta \) where \( \lambda = \frac{\log\beta}{\log \alpha} \).</p>
<p>The paper carefully presents several variations of the Kelly gamble, establishes bounds, and performs a comparative study, but what is highlighted above constitutes the heart of the matter for realistic applications.</p>
<hr>
</div>
                </div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/Time%20series/" class="u-url">Time series</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Your Name
                    </span></p>
            <p class="dateline">
            <a href="posts/Time%20series/" rel="bookmark">
            <time class="published dt-published" datetime="2019-02-04T19:34:54Z" itemprop="datePublished" title="2019-02-04 19:34">2019-02-04 19:34</time></a>
            </p>
                        <p class="commentline">
        
    <a href="posts/Time%20series/#disqus_thread" data-disqus-identifier="cache/posts/ts.html">Comments</a>


                </p>
</div>
            </header><div class="e-content entry-content">
                    <div>
<h2>Time Series</h2>
<p>Educated as an Electrical engineer early in life and having more recently worked as a 'quant' for many years, the topic of time series analysis has evolved from a clean one to a bewildering hodgepodge of complications; pretty much all of it because of the stochastic nature of markets.</p>
<p>Some fundamental issues:</p>
<ul>
<li>
<p>Transactional - data from markets are records of transactional events and not uniformly sampled; therefore, times series are non-homogeneous.</p>
</li>
<li>
<p>Stationarity - market data are not necessarily stationary and often have complicated time-delayed feedback structures. Moreover, change points (or regime shifts) are not uncommon.</p>
</li>
<li>
<p>Ergodicity - practitioners often analyze time series to aid in prediction; but under what condition can the histories of (single realizations of) sampled paths be considered representative of future behavior?</p>
</li>
</ul>
<p>There are other issues like low signal-to-noise, high dimensionality, missing values, and outliers. Although these are important, the three highlighted undermine the applicability of traditional methods.</p>
<hr>
<h3>Transactional</h3>
<p>Traditionally an engineer dealing with signals mainly work with Fourier transforms and related objects.</p>
<p>$$
f(x) = \int_{-\infty}^{\infty} \hat f(\xi) e^{2 \pi i \xi x} d\xi 
$$</p>
<p>Clean and elegant. This formalism is fundamental and will not likely ever diminish in stature. Yet quantitative-minded participants in finance, in particular currency traders of the late 1990's, pointed out a significant characteristics of the data of their trade that needed addressing:
<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=208278">Operators on Inhomogeneous Time Series</a>. A central idea underlying inhomogeneous time series is that 'time' is proportional to the density of 'activity'. With regards to the 'information' content of inhomogeneous market data, this paper <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1989555">'Discerning Information from Trade Data'</a> describes a aggregated 'tick' or 'bar' approach - essentially integrating pieces of data partitioned by time into informational units for analysis. Aside: a good presentation of the many pitfalls encountered by financial professionals are in Marcos Lopez de Prado's <a href="https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482109">'Advances in Financial Machine Learning'</a>. A Jupyter notebook in the blog post <a href="http://www.blackarbs.com/blog/exploring-alternative-price-bars">'Exploring Alternative Price Bars'</a> illustrates this approach.</p>
<hr>
<h3>Non-Stationary Data</h3>
<p>Over an intermediate time-span, market data fluctuate in a relatively well-behaved manner, and statistical observations like mean-reversion are relevant and expected. On a longer time-scale, statistically 'rare' events are not so uncommon in real markets. In other words, statistical models stop making sense when markets go wild - a good indicator that market prices are not necessarily stationary (see <a href="https://www.youtube.com/watch?v=Pn_RiDbK82M&amp;t=160s">Integration, Cointegration, and Stationarity</a> for examples of non-stationary time series that are rather tame. Beware though that using integer differentiation may remove information content. See chapter 5 of <a href="https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482109">'Advances in Financial Machine Learning'</a> or look up fractional differentiation for financial data.)</p>
<!---
memory effects
-->

<p>Bottom line is that market data needs to be analyzed and transformed before statistical methods are applicable as intended. Then again, many methods of Machine Learning work well in practice without a rigorous understanding of why they work. In any case, a usual suspect for why a model has limited or no predictive ability post construction is because the model was formulated with non-stationary data. Good sites examining fundamental issues in applying scientific theory to economics is <a href="https://ergodicityeconomics.com/">Ergodicity Economics</a> and to markets is <a href="http://www.quantresearch.info/">Quantitative Finance</a>.</p>
<hr>
<h3>Ergodicity</h3>
<p>Equivalence of ensemble-average and time-average with respect to some sampled statistics is an important subject. <a href="https://arxiv.org/abs/1401.7224">Gaveau and Schulman</a> questioned whether ergodicity is a reasonable hypothesis - many applications only require 'reasonably'-sized samples. An article by <a href="https://statweb.stanford.edu/~cgates/PERSI/papers/mixing.pdf">Persi Diaconis</a> explore this for practitioners. <a href="https://www.youtube.com/watch?v=LGqOH3sYmQA">Ole Peters</a> has put forth commendable effort at explaining
the real-world implications of using ensemble quantities when individuals experience but one life. <a href="https://www.youtube.com/watch?v=qA_6BWkC4og">Nassim Taleb</a> discusses ergodicity from a trader's perspective.</p>
<p>Even though the age of immense computing power and massive data collection is upon us, A better understanding of how many representative examples are enough for a good approximation is more important then ever. Reason being that society is putting more faith than ever into systems trained by examples, whether they are generated (games and such) or collected.</p>
<hr>
</div>
                </div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/first-tiny-bit/" class="u-url">first tiny bit</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Your Name
                    </span></p>
            <p class="dateline">
            <a href="posts/first-tiny-bit/" rel="bookmark">
            <time class="published dt-published" datetime="2019-02-02T15:07:54Z" itemprop="datePublished" title="2019-02-02 15:07">2019-02-02 15:07</time></a>
            </p>
                        <p class="commentline">
        
    <a href="posts/first-tiny-bit/#disqus_thread" data-disqus-identifier="cache/posts/first-tiny-bit.html">Comments</a>


                </p>
</div>
            </header><div class="e-content entry-content">
                    <p>Trying out different site generators. Nikola is first. Yea! \( e^{ix} = \cos{x} + i \sin{x} \) works fine!
Now try adding [GatsbyJS](<a class="reference external" href="https://www.gatsbyjs.org/">https://www.gatsbyjs.org/</a>) under the Nikola structure to take advantage of the dynamic features of that infrastructure.</p>
                </div>
            </article>
</div>
    

    
        
       <script>var disqus_shortname="nikolademo";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha256-ExtbCSBuYA7kq1Pz362ibde9nnsHYPt6JxuxYeZbU+c=" crossorigin="anonymous"></script><script>
                renderMathInElement(document.body,
                    {
                        delimiters: [
                            {left: "$$", right: "$$", display: true},
                            {left: "\\[", right: "\\]", display: true},
                            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
                            {left: "\\(", right: "\\)", display: false}
                        ]
                    }
                );
            </script><!--End of body content--><footer id="footer">
            Contents Â© 2019         <a href="mailto:joe@demo.site">Your Name</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


        <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>
